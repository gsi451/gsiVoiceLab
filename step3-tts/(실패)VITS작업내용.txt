작업내용 기록

📂 1. var 폴더에 step3-tts 폴더 생성
sudo mkdir /var/step3-tts
sudo mkdir /var/step3-tts/kss-dataset

👤 2. gsi 계정에게 접근 권한 부여
sudo chown gsi:gsi /var/step3-tts
sudo chmod 755 /var/step3-tts/kss-dataset


📦 3. 데이터셋 복사
sudo cp -r /home/gsi/kss-root/* /var/step3-tts/kss-dataset/
kaggle-dataset 폴더 안에 kss-root 폴더가 들어가는 게 아니라, 
kss-root 안의 내용물만 kss-dataset에 옮기고 싶다면 이렇게


🐍 4. 파이썬 가상환경 생성 및 활성화
python3.10 -m venv vits-env
source vits-env/bin/activate

5. pip 최신화 + 캐시 경로 변경
pip install --upgrade pip
export PIP_CACHE_DIR=/var/tmp


6. 필수 패키지 설치
sudo apt update
sudo apt install -y ffmpeg
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118
pip install numpy librosa phonemizer matplotlib tensorboard tqdm


7. VITS 코드 다운로드 및 requirements 설치
git clone https://github.com/jaywalnut310/vits.git
cd vits

pip install -r requirements.txt
아래와 같이 수정후 진행
numpy==1.21.6
scipy==1.9.3
matplotlib==3.5.3
contourpy==1.1.0
phonemizer==3.2.1
librosa==0.10.1
llvmlite==0.41.1
numba==0.58.0
tensorboard==2.14.0
tqdm==4.66.1
cachetools==5.5.2
google-auth==2.39.0
google-auth-oauthlib==1.0.0
oauthlib==3.2.2
pyasn1==0.6.1
pyasn1-modules==0.4.2
requests-oauthlib==2.0.0
rsa==4.9.1
wheel==0.45.1

📌 설치 명령
이 파일로 requirements.txt 저장하고 아래 명령어 실행:

pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118
※ cu118 전용 패키지(torch/torchaudio/torchvision)는 --extra-index-url 옵션으로 같이 설치 가능해.

8. wav파일 패딩 및 문자열 토크나이저 진행
```
# transscript.v.1.4.txt 파일 토큰화 메뉴얼

1. transcript_conv.py 를 사용해서 우선 필요한 항목 첫번째와 3번재를 추출해서 새로운 파일 conv_transcript.v.1.4.txt 로 생성합니다.
2. tokenize_text.py 를 사용해서 conv_transcript.v.1.4.txt 파일의 한글을 토큰화 진행하고 tokenized_transcript.v.1.4.txt 로 생성합니다.
3. token_test.py 를 사용해서 토큰화된 부분들이 정확하게 일치하는지 검증합니다.

# wav 파일 길이 동일하게 패딩처리

1. pad_wav_files.py 를 사용해서 제일 긴 파일을 찾아내고 해당 길이와 동일하게 패딩을 추가해서 저장한다.

pip install numpy librosa soundfile tqdm
python pad_wav_files.py

```

9. config.json 생성 및 필요한 폴더 추가

```
{
    "train_config": {
      "batch_size": 32,
      "learning_rate": 0.0001,
      "lr_decay_rate": 0.999,
      "lr_decay_steps": 50000,
      "max_epoch": 1000,
      "steps_per_checkpoint": 1000,
      "checkpoint_dir": "/var/step3-tts/checkpoints",
      "log_dir": "/var/step3-tts/logs",
      "sample_rate": 44100,
      "num_mels": 80,
      "num_freq": 1025,
      "hop_size": 256,
      "win_size": 1024,
      "frame_shift_ms": 12.5,
      "preemphasis": 0.97,
      "max_db": 100,
      "min_db": -100,
      "ref_level_db": 20,
      "n_fft": 2048,
      "hop_length": 256,
      "win_length": 1024,
      "use_cuda": true,
      "cuda_device": 0
    },
    "data_config": {
      "text_cleaners": ["korean_cleaners"],
      "input_texts_file": "/var/step3-tts/kss-dataset-conv/tokenized_transcript.v.1.4.txt",
      "audio_dir": "/var/step3-tts/kss-dataset-conv/kss",
      "train_output_dir": "/var/step3-tts/output"
    },
    "model_config": {
      "encoder_hidden_size": 256,
      "decoder_hidden_size": 256,
      "num_layers": 3,
      "embedding_size": 256,
      "attention_type": "multihead",
      "dropout": 0.1
    },
    "inference_config": {
      "use_mel": true,
      "synthesis_mode": "fast",
      "pretrained_model_path": "/path/to/pretrained/model"
    }
  }
  
```

```
/var/step3-tts/checkpoints	모델 체크포인트 저장 경로 (G_10000.pth 등)
/var/step3-tts/logs	학습 로그, TensorBoard 로그 저장 경로
/var/step3-tts/output	학습 중간 결과물 출력 (샘플 wav 등)
/var/step3-tts/kss-dataset-conv/kss	KSS wav 파일 폴더
/var/step3-tts/kss-dataset-conv/tokenized_transcript.v.1.4.txt	텍스트

sudo mkdir -p /var/step3-tts/checkpoints
sudo mkdir -p /var/step3-tts/logs
sudo mkdir -p /var/step3-tts/output

sudo chown -R gsi:gsi /var/step3-tts
```

10. monotonic_align 컴파일
```
cd /var/step3-tts/vits/monotonic_align

pip install cython

# 컴파일 실행
python setup.py build_ext --inplace

# 파일 이동
mv /var/step3-tts/vits/monotonic_align/monotonic_align/core.cpython-310-x86_64-linux-gnu.so \
   /var/step3-tts/vits/monotonic_align/
```

11. 빌드 및 실행
```
python3 ./vits/train.py --config /var/step3-tts/config.json --model vits

# 필요시 이 부분도 해야함
pip install numpy==1.23.5
pip install unidecode
```

12. 추가로 코드 수정
```
vits/monotonic_align/__init__.py
#from .monotonic_align.core import maximum_path_c
from .core import maximum_path_c

vits/train.py
os.environ['MASTER_PORT'] = '50000'
```

# 다시 해봐야 하는 부분
- JSON 부분도 계층 형태로 다시 변경해서 처리하자.
- vits 부분도 새로 가져와서 다시 재구성하자.
- 소스를 몇번 보니 이해가 되네.. 다시 수정하고 다시 학습 하도록 하자.
- kss-conv 는 이미 만들어져 있으니 그 부분을 그대로 사용하면 된다.
- 다음 스텝을 하는거야~~


pt를 지우고 다시 시작할때
find /var/step3-tts/kss-conv -name "*.spec.pt" -delete

python3 ./vits/train.py --config /var/step3-tts/config.json --model vits


# 이후 참고한 자료들
https://arca.live/b/aispeech/72903471
